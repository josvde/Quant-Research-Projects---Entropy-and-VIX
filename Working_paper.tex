\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyhead[L]{\slshape \MakeUppercase{Quantitative Research Projects}}
\fancyhead[R]{\slshape {BETA SIGMA CLUB}}
\fancyfoot[C]{\thepage}


\begin{document}

\begin{titlepage}
\begin{center}
\vspace*{1cm}
\vfill
\line(1,0){400}\\[1mm]
\huge{\textbf{Quantitative Research Projects}}\\[3mm]
\Large{\textbf{By BETA SIGMA CLUB}}\\[1mm]
\line(1,0){400}\\[3mm]
\vfill
\today

\end{center}
\end{titlepage}

\section{Abstract and Keywords}
\textbf{Abstract:} Comparision of the standard measure for stock market volatility, standard deviation, with an alternative measure, entropy. \\

\noindent \textbf{Keywords:}
\begin{itemize}
\item Shannon Entropy
\item Tsallis Entropy
\item Alternative stock market volatility measures
\item Volatility measurement
\item Econophysics
\end{itemize}

\noindent \textbf{Questions:}
\begin{itemize}
\item Do we include \textbf{time variant} volatility measures like the ARCH (Autoregressive Conditional Heteroscedastic) model in our comparison?
\end{itemize}

\newpage
\section{Introduction}
Before diving deep into Entropy's application as a measure of volatility, we need to introduce how we can use physics in financial markets.
\subsection{Econophysics}
Econophysics is an interdisciplinary research field where physics is used to solve problems in Economics. The applications of physics, and more particularly statistical physics, in economics started being used as people realised that economics and markets were not efficient. Thus, a more statistical approach was needed. The stochastic processes and nonlinear dynamics from statistical physics later founded the basis of statistical finance. In this paper, we are going to handle entropy as a new, and more powerful stock market volatility metric. 

\section{Physical Aspects of Entropy}
Entropy finds its origin in thermodynamics, a branch of physics, and is often described as the rate of disorder randomness, or uncertainty. Ludwig Boltzmann, an Austrian physicist defined entropy as the number of possible microscopic states of individual atoms and molecules of a system. With this, he introduced the concept of statistical disorder and probability distributions. Boltzmann's famous formula for entropy (denoted by S) is defined as:
\begin{equation*}
    S = k_{B} \ln W
\end{equation*}
Where W is the number of possible microscopic states corresponding to the macroscopic state of a system.
\begin{equation*}
    W = N! \ \prod_{i}^{} \frac{1}{N_{i}!}
\end{equation*}
and N the amount of \textit{identical} particles.

\section{Mathematical Aspects of Entropy: Louis and Hamza}
\section{Financial Engineering section: Hamza, Edoardo and Jos}


\end{document}